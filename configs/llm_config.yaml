# LLM Configuration for AI Agent Framework
# This file configures the LLM providers and their settings

llm:
  # Default provider to use when no specific provider is requested
  default_provider: "openai"
  
  # Fallback order when the primary provider fails
  fallback_order:
    - "anthropic"
    - "openai"
  
  # Provider configurations
  providers:
    # OpenAI Configuration
    openai:
      api_key: "${OPENAI_API_KEY}"  # Environment variable
      model: "gpt-3.5-turbo"
      max_tokens: 1000
      temperature: 0.7
      timeout: 30
      # Optional: for Azure OpenAI
      # base_url: "https://your-resource.openai.azure.com/"
      # organization: "your-org-id"
    
    # Anthropic Configuration
    anthropic:
      api_key: "${ANTHROPIC_API_KEY}"  # Environment variable
      model: "claude-3-sonnet-20240229"
      max_tokens: 1000
      temperature: 0.7
      timeout: 30
      # Optional: custom base URL
      # base_url: "https://api.anthropic.com"

# Example environment variables to set:
# export OPENAI_API_KEY="sk-your-openai-key-here"
# export ANTHROPIC_API_KEY="sk-ant-your-anthropic-key-here"